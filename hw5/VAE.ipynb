{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8B8S9yHqAOF"
   },
   "source": [
    "# VAE\n",
    "Variational autoencoder [1] models inherit autoencoder architecture, but  use variational approach for latent representation learning. In this homework, we will implement VAE and quantitatively measure the quality of the generated samples via Inception score [2,3].\n",
    "\n",
    "[1] Auto-Encoding Variational Bayes, Diederik P Kingma, Max Welling 2013\n",
    "https://arxiv.org/abs/1312.6114\n",
    "\n",
    "[2] Improved techniques for training gans, Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Rad- ford, A., and Chen, X. 2016\n",
    "In Advances in Neural Information Processing Systems \n",
    "\n",
    "[3] A note on inception score, Shane Barratt, Rishi Sharma 2018\n",
    "https://arxiv.org/abs/1801.01973\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2Cy05g40Epk"
   },
   "source": [
    "# PART I. Train a good VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FRksiBgqlAh"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ooy_uAZNvHWT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# A bunch of utility functions\n",
    "\n",
    "def show_images(images):\n",
    "    images = images.view(images.shape[0], -1).detach().cpu().numpy()\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg, sqrtimg]))\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_img(x):\n",
    "    return 2 * x - 1.0\n",
    "\n",
    "def deprocess_img(x):\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def rel_error(x, y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4crSgXuSrJ2L"
   },
   "source": [
    "## Dataset\n",
    "We will be working on the MNIST dataset, which is 60,000 training and 10,000 test images. Each picture contains a centered image of white digit on black background (0 through 9). This was one of the first datasets used to train convolutional neural networks and it is fairly easy -- a standard CNN model can easily exceed 99% accuracy. \n",
    " \n",
    "\n",
    "**Heads-up**: Our MNIST wrapper returns images as vectors. That is, they're size (batch, 784). If you want to treat them as images, we have to resize them to (batch,28,28) or (batch,28,28,1). They are also type np.float32 and bounded [0,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVyQDutTvZ2-"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                      # [0,1]\n",
    "    # transforms.Lambda(lambda x: preprocess_img(x))  # [-1,1]\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "batch_size = 16\n",
    "mnist_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U35atJNUvlY6"
   },
   "outputs": [],
   "source": [
    "# Show a batch\n",
    "data_iter = iter(mnist_loader)\n",
    "images, labels = next(data_iter)\n",
    "show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFs-HgHH-Edo"
   },
   "outputs": [],
   "source": [
    "X_DIM = images[0].numel()\n",
    "num_samples = 100000\n",
    "num_to_show = 100\n",
    "\n",
    "# Hyperparamters. Your job is to find these.\n",
    "# TODO:\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "num_epochs = None\n",
    "batch_size = None\n",
    "Z_DIM = None\n",
    "learning_rate = None\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qe4AkjK9vlfz"
   },
   "source": [
    "## Encoder\n",
    "Our first step is to build a variational encoder network $q_\\phi(z \\mid x)$. \n",
    "\n",
    "**Hint:** Use four Linear layers.\n",
    "\n",
    "The encoder should return two tensors of shape `[batch_size, z_dim]`, which  corresponds to the mean $\\mu(x_i)$ and diagonal log variance $\\log \\sigma(x_i)^2$ of each of the `batch_size` input images. Note, we want to make it return log of the variance for numerical stability.\n",
    "\n",
    "**WARNING:** Do not apply any non-linearity to the last activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bahWhGs5wt3W"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim=Z_DIM, x_dim=X_DIM):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.x_dim = x_dim\n",
    "        # TODO: implement here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: implement here\n",
    "        mu, log_var = out[:, :self.z_dim], out[:, self.z_dim:]\n",
    "        return mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHoTlHSK1Xt2"
   },
   "outputs": [],
   "source": [
    "# TODO: implement reparameterization trick\n",
    "def sample_z(mu, log_var):\n",
    "    # Your code here for the reparameterization trick.\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    samples = None\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    return samples\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMEOgw0x1bpf"
   },
   "source": [
    "## Decoder\n",
    "Now to build a decoder network $p_\\theta(x \\mid z)$. Use four linear layers.\n",
    "\n",
    "In this exercise, we will use continuous Bernoulli MLP decoder where $p_\\theta(x \\mid z)$ is modeled with multivariate continuous Bernoulli distribution, in contrast to the Gaussian distribution we discussed in the lecture, as following (see Appendix C.1 in the original paper and https://arxiv.org/abs/1907.06845 for more details),\n",
    "\n",
    "$\\log p(x \\mid z) = \\sum_{i=1} x_i \\log \\lambda(z)_i + (1-x_i) \\log (1-\\lambda(z)_i) + \\log C(\\lambda(z)_i)$,\n",
    "\n",
    "where $\\lambda(z)_i$ is the parameter of continuous Bernoulli distribution corresponding to $i$-th pixel. (Note that $\\lambda(z)$ is corresponding to $\\mathrm{sigmoid}(x\\_\\text{logit})$ in this implementation, and it also can be seen as the decoded image for latent $z$.)\n",
    "\n",
    "Note, the output of the decoder should have shape `[batch_size, x_dim]` and should output the unnormalized logits of $x_i$.\n",
    "\n",
    "**WARNING:** Do not apply any non-linearity to the last activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RXB7XOl1g72"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim=Z_DIM, x_dim=X_DIM):\n",
    "        super(Decoder, self).__init__()\n",
    "        # TODO: implement here\n",
    "\n",
    "    def forward(self, z):\n",
    "        # TODO: implement here\n",
    "        return x_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xOZpzso2w3Y"
   },
   "source": [
    "## Loss definition\n",
    "Compute the VAE loss. \n",
    "1. For the reconstruction loss, you might find `F.binary_cross_entropy_with_logits` useful.\n",
    "2. For the kl loss, we discussed the closed form kl divergence between two gaussians in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40qNrPkT3D8s"
   },
   "outputs": [],
   "source": [
    "def vae_loss(x, x_logit, z_mu, z_logvar):\n",
    "    recon_loss = None\n",
    "    kl_loss = None\n",
    "    \n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    vae_loss = torch.mean(recon_loss + kl_loss)\n",
    "    return vae_loss, torch.mean(recon_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJgFsfCDzJWu"
   },
   "source": [
    "## Optimizing our loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P27H8vbu54Ds"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Q = Encoder().to(device)\n",
    "P = Decoder().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(Q.parameters()) + list(P.parameters()), lr=learning_rate)\n",
    "# MNIST DataLoader (shuffle=True)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTbSDHNLcNXd"
   },
   "source": [
    "Visualize generated samples before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxMtTL6IcICm"
   },
   "outputs": [],
   "source": [
    "z_gen = torch.randn(num_to_show, Z_DIM).to(device)\n",
    "x_gen = P(z_gen)\n",
    "imgs_numpy = torch.sigmoid(x_gen).detach().cpu()\n",
    "show_images(imgs_numpy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6xVN3sBzWD3"
   },
   "source": [
    "## Training a VAE!\n",
    "If everything works, your batch average reconstruction loss should drop below 95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zbn5KW9T-4BF"
   },
   "outputs": [],
   "source": [
    "iter_count = 0\n",
    "show_every = 200\n",
    "\n",
    "# ----- Training Loop -----\n",
    "for epoch in range(num_epochs):\n",
    "    for x_i, _ in mnist_loader:\n",
    "        x_i = x_i.view(x_i.size(0), -1).to(device)   # Flatten and move to device\n",
    "        \n",
    "        z_mu, z_logvar = Q(preprocess_img(x_i))\n",
    "        z_i = sample_z(z_mu, z_logvar)\n",
    "        x_logit = P(z_i)\n",
    "\n",
    "        loss, recon_loss = vae_loss(x_i, x_logit, z_mu, z_logvar)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter_count % show_every == 0:\n",
    "            print(f'Epoch: {epoch}, Iter: {iter_count}, Loss: {loss.item():.4f}, Recon: {recon_loss.item():.4f}')\n",
    "            # imgs_numpy = torch.sigmoid(x_logit).detach().cpu()\n",
    "            # show_images(imgs_numpy[:16])\n",
    "            # plt.show()\n",
    "        iter_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJR3cerpcSPu"
   },
   "source": [
    "Visualize generated samples after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duZZIrDGbmkb"
   },
   "outputs": [],
   "source": [
    "z_gen = torch.randn(num_to_show, Z_DIM).to(device)\n",
    "x_gen = P(z_gen)\n",
    "imgs_numpy = torch.sigmoid(x_gen).detach().cpu()\n",
    "show_images(imgs_numpy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybqA40bFzzd0"
   },
   "source": [
    "# PART II. Compute the inception score for your trained VAE model\n",
    "In this part, we will quantitavely measure how good your VAE model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjSxHv5JOcfd"
   },
   "source": [
    "### Train a classifier\n",
    "We first need to train a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mNNF_tJJzj0"
   },
   "outputs": [],
   "source": [
    "# ----- Hyperparameters -----\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "# ----- Data Preparation -----\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f'{len(train_dataset)} train samples')\n",
    "print(f'{len(test_dataset)} test samples')\n",
    "\n",
    "# ----- Model Definition -----\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def prob(self, x):\n",
    "        x = self.forward(x)\n",
    "        prob = F.softmax(x, dim=-1)\n",
    "        return prob\n",
    "\n",
    "model = MLPClassifier().to(device)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----- Training -----\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# ----- Evaluation -----\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print('Test accuracy:', correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3i4W8U3u0mCZ"
   },
   "source": [
    "### Verify the trained classifier on the generated samples\n",
    "Generate samples and visually inspect if the predicted labels on the samples match the actual digits in generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLh6RRuL0vAi"
   },
   "outputs": [],
   "source": [
    "z_gen = torch.randn(num_samples, Z_DIM).to(device)\n",
    "x_gen = P(z_gen)\n",
    "imgs_numpy = torch.sigmoid(x_gen[:num_to_show]).detach().cpu()\n",
    "show_images(imgs_numpy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSecn8Mqc4kz"
   },
   "outputs": [],
   "source": [
    "preds = torch.argmax(model(torch.sigmoid(x_gen[:20])), dim=1)\n",
    "print(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6OMwL6FA1jX6"
   },
   "source": [
    "### Implement the inception score\n",
    "Implement Equation 1 in the reference [3]. Replace expectation in the equation with empirical average of `num_samples` samples. Don't forget the exponentiation at the end. You should get Inception score of at least 9.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T90AT5V8Mold"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # TODO: implement here\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    inception_score = None\n",
    "    pass\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "print(f'Inception score: {inception_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0r7aK4v2FwE"
   },
   "source": [
    "### Plot the histogram of predicted labels\n",
    "Let's additionally inspect the class diversity of the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "woxFDpsnb2ZD"
   },
   "outputs": [],
   "source": [
    "hist_preds = torch.argmax(model(torch.sigmoid(x_gen)), dim=1).cpu().numpy()\n",
    "plt.hist(hist_preds, bins=np.arange(11)-0.5, rwidth=0.8, density=True)\n",
    "plt.xticks(range(10))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
